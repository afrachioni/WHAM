<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
           "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<meta name="GENERATOR" content="TtHgold 4.00">
 <style type="text/css"> div.p { margin-top: 7pt;}</style>
 <style type="text/css"><!--
 td div.comp { margin-top: -0.6ex; margin-bottom: -1ex;}
 td div.comb { margin-top: -0.6ex; margin-bottom: -.6ex;}
 td div.hrcomp { line-height: 0.9; margin-top: -0.8ex; margin-bottom: -1ex;}
 td div.norm {line-height:normal;}
 span.roman {font-family: serif; font-style: normal; font-weight: normal;} 
 span.overacc2 {position: relative;  left: .8em; top: -1.2ex;}
 span.overacc1 {position: relative;  left: .6em; top: -1.2ex;} --></style>
 

<title>No Title</title>


<center><b>An implementation of WHAM: the Weighted Histogram Analysis Method</b> <br />
<b>Version 2.0.7</b> <br />
<br /><br /><br />
<b>Alan Grossfield</b> <br />

</center>

<div class="p"><!----></div>
 <h2><a name="tth_sEc1">
1</a>&nbsp;&nbsp;Introduction</h2>

<div class="p"><!----></div>
These programs (wham and wham-2d) implement the Weighted Histogram
Analysis Method of Kumar, et al ("Multidimensional free-energy
calculations using the weighted histogram analysis method",
J. Comput. Chem., 16:1339-1350, 1995).  The code generally
follows the notation used by Benoit Roux ("The calculation of the
potential of mean force using computer simulations", Comput. Phys. Comm.,
91:275-282, 1995).  Consult these papers for the theoretical background
and justification for the method.

<div class="p"><!----></div>
This code is available for download from my web page
(<a href="http://membrane.urmc.rochester.edu/content/wham/"><tt>http://membrane.urmc.rochester.edu/content/wham/</tt></a>). The code doesn't
change all that often, but it's probably worth checking periodically.  If you
run into trouble using these programs, feel free to contact me
(alan_grossfield@urmc.rochester.edu), and I'll try to help you.  This code
is available under the GPL and BSD licenses, as you prefer.  The exception to
this licensing is a set of routines from Numerical Recipes, which are not mine
to give away.  

<div class="p"><!----></div>
If you use this code as part of an original piece of research, I'd
appreciate a reference or acknowledgment.  There's no publication to
reference, so please use something like:

<div class="p"><!----></div>
Grossfield, A, "WHAM: an implementation of the weighted histogram analysis 
method", <a href="http://membrane.urmc.rochester.edu/content/wham/"><tt>http://membrane.urmc.rochester.edu/content/wham/</tt></a>, version
XXXX

<div class="p"><!----></div>
 For that matter, just letting me know what you're using my code for
would be nice, although again I don't insist upon it.

<div class="p"><!----></div>
Suggestions and patches are welcome.  

<div class="p"><!----></div>
 <h2><a name="tth_sEc2">
2</a>&nbsp;&nbsp;New in release 2.0.7</h2>

<div class="p"><!----></div>
I messed up the ability to switch units from kcal to kJ: in addition to
defining k_B in the header files, I also had a define in wham_2d.c.  Caught
by Yi Yao of UNC.

<div class="p"><!----></div>
 <h2><a name="tth_sEc3">
3</a>&nbsp;&nbsp;New in release 2.0.6</h2>

<div class="p"><!----></div>
The primary new feature in version 2.0.6 is the ability to exclude regions
of a 2D reaction coordinate from a calculation, which we're calling
"masking".  This is useful in cases where the PMF is being used to sample a
pathway that is two dimensional, but where large areas of the 2D surface are
either uninteresting or physically unattainable; for example, if the two
reaction coordinates are RMSDs from 2 distinct structures, it is almost
certainly impossible to sample the region where the RMS distance to each
structure is very small.  In practice, you could generally do the calculation
anyway and just accept lots of NaNs and Infs floating around in the output,
but sometimes that would fail and this way is far cleaner and robust.  In
this case, I chose to implement a very simple automasking procedure, such
that any bin that has no data from any window is excluded.  I suppose I could
further generalize it, so that any bin with fewer than N points is excluded,
but I haven't done that yet.

<div class="p"><!----></div>
There's one other trivial but often requested feature in version 2.0.6: if
you prefer to work in SI units, I've made it easier to switch energy units 
from kcal to kJ (the units of your reaction coordinate are, as always, up to
you).  It's a compile-time choice, but I figure that's fine because very few
people switch units constantly.  The switch is easy - before you build the
code, edit <tt>wham/wham.h</tt> and <tt>wham-2d/wham-2d.h</tt> and change which
version of the constant <tt>k_B</tt> is defined.

<div class="p"><!----></div>
 <h2><a name="tth_sEc4">
4</a>&nbsp;&nbsp;New in release 2.0.4 and 2.0.5</h2>

<div class="p"><!----></div>
Version 2.0.5 is a trivial patch on 2.0.4, upping the length of lines allowed
when reading files.

<div class="p"><!----></div>
Release 2.0.4 has seen major revision to the bootstrap error analysis.  
I've known for a while that the way I computed the uncertainty in the free
energy was suboptimal, since it just extrapolated from the uncertainty in the
probability using the assumption that the fluctuations were gaussianly
distributed.  I knew this wasn't a great assumption, but Michael Shirts
showed me data showing just how bad it was.  So, in this version, we're doing
something different.  For 1D wham, we're directly computing the fluctuations
in the PMF at each bin, aligning the pmfs such that their partition functions
are all 1; this amounts to shifting them so that their Boltzmann-weighted
free energies are the same.  I think the errors make more sense now.

<div class="p"><!----></div>
For 2D wham, I think doing this analysis uncovered some other flaws in how the
error analysis is done, ones that to be honest I'm not totally sure how to
fix.  For now, I'm simply removing the option to do bootstrapping in 2D.  I
hope to put it back once I solve the problem, in which case I'll make another
release.

<div class="p"><!----></div>
Many thanks to Michael Shirts, for helpful discussions and contributing much
of the code changes that went into this release.

<div class="p"><!----></div>
 <h2><a name="tth_sEc5">
5</a>&nbsp;&nbsp;Installation</h2>

<div class="p"><!----></div>
Untarring wham.tgz will create a directory wham/, which in turn contains
several directories (wham/ wham-2d/ doc/ nr/).   

<div class="p"><!----></div>
Before you build the code, you need to choose your units for energy.  If you
want kcal/mol, do nothing.  If you prefer to work in kJ, you need to edit
2 files, <tt>wham/wham.h</tt> and <tt>wham-2d/wham-2d.h</tt>.  In each case, near the
top of the file you'll see a pair of lines that look like 

<div class="p"><!----></div>

<pre>
#define&nbsp;k_B&nbsp;0.001982923700&nbsp;//&nbsp;Boltzmann's&nbsp;constant&nbsp;in&nbsp;kcal/mol&nbsp;K
//#define&nbsp;k_B&nbsp;&nbsp;0.0083144621&nbsp;//&nbsp;Boltzmann's&nbsp;constant&nbsp;kJ/mol-K

</pre>

<div class="p"><!----></div>
To get kJ, you simply remove the "//" from the second line and put it
before the first line, and save the file.  In principle, you can do just wham
or just wham-2d, but I recommend against it for your own sanity.  

<div class="p"><!----></div>
To build the standard 1-D wham code on a machine which has gcc, you should

<div class="p"><!----></div>

<pre>
&nbsp;&nbsp;&nbsp;&nbsp;cd&nbsp;wham
&nbsp;&nbsp;&nbsp;&nbsp;make&nbsp;clean
&nbsp;&nbsp;&nbsp;&nbsp;make

</pre>

<div class="p"><!----></div>
(which will delete all object files and executables, and build the wham
executable).  By default, the Makefile uses the gcc compiler, but I also have
flags present for the Intel compiler, plus the native compilers for Irix and
Tru64.  The latter two have not been tested recently, but ought to work,
since at various times this code has been used successfully on various
flavors of linux, MacOS X, AIX, Irix, and Tru64.  If you find that you need
to do anything special to make it work on your particular system, I'd
appreciate it if you could let me know so I can add to the Makefile.

<div class="p"><!----></div>
To build the 2-D version,  say

<div class="p"><!----></div>

<pre>
&nbsp;&nbsp;&nbsp;&nbsp;cd&nbsp;wham-2d
&nbsp;&nbsp;&nbsp;&nbsp;make&nbsp;clean
&nbsp;&nbsp;&nbsp;&nbsp;make

</pre>

<div class="p"><!----></div>
Several other directories are also created (doc/, which you presumably found
because you're reading this, and nr/, which contains a couple of files from
Numerical Recipes).  You don't need to do anything with these directories.

<div class="p"><!----></div>
 <h2><a name="tth_sEc6">
6</a>&nbsp;&nbsp;Command line arguments and file formats</h2>

<div class="p"><!----></div>
To get a listing of the command line arguments for either wham or wham-2d,
just run the command without any arguments.  Optional arguments are
included in brackets.  Both programs will echo their command line into the
output file, to help you figure out what you did.

<div class="p"><!----></div>
     <h3><a name="tth_sEc6.1">
6.1</a>&nbsp;&nbsp;wham</h3>

<div class="p"><!----></div>
      <h4><a name="tth_sEc6.1.1">
6.1.1</a>&nbsp;&nbsp;Command line arguments for WHAM</h4>

<div class="p"><!----></div>

<pre>
wham&nbsp;[P|Ppi|Pval]&nbsp;hist_min&nbsp;hist_max&nbsp;num_bins&nbsp;tol&nbsp;temperature&nbsp;numpad&nbsp;&nbsp;\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;metadatafile&nbsp;freefile&nbsp;[num_MC_trials&nbsp;randSeed]

</pre>

<div class="p"><!----></div>
The first (optional) argument specifies the periodicity of the reaction
coordinate.  For a nonperiodic reaction coordinate (a distance, for
example), it should be left out.  "P" means that the reaction coordinate
has a periodicity of 360, appropriate for angles. "Ppi" specifies a
periodicity of 2*pi, appropriate for angles measured in radians.  "Pval"
specifies periodicty of some arbitrary amount, val, which should be an
integer or floating point number.  For example, "P180.0" would be
appropriate for an angle with twofold symmetry. 

<div class="p"><!----></div>
hist_min and hist_max specify the boundaries of the histogram.  As a rule,
all data points outside the range (hist_min, hist_max) are silently
ignored.  The only exception is that if an entire trajectory is outside the
range, the program halts with an error message.  The solution is to remove
that file from the metadata file.  hist_min and hist_max should be floating
point numbers.

<div class="p"><!----></div>
num_bins specifies the number of bins in the histogram, and as a result the
number of points in the final PMF.  It should be an integer.

<div class="p"><!----></div>
tol is the convergence tolerance for the WHAM calculations.  Specifically,
the WHAM iteration is considered to be converged when no F<sub>i</sub> value for any
simulation window changes by more than tol on consecutive iterations.  As
the program runs, it prints the average change in the F values for the most
recent iteration.  Obviously, this number will be smaller than tol
before the computation converges, because convergence is triggered by the
largest change as opposed to the average.

<div class="p"><!----></div>
temperature is a floating point number representing the temperature in
Kelvin at which the weighted histogram calculation is performed.  This does
not have to be the temperature at which the simulations were performed (see
below for discussion).

<div class="p"><!----></div>
numpad specifies the number of "padding" values that should be printed for
periodic PMFs.  This number should be set to 0 for aperiodic reaction
coordinates.  It doesn't actually affect the calculation in any way.
Rather, it just alters the final printout of the free energy, to make
plotting of periodic reaction coordinates simpler.  This is more important
for wham-2d than wham.

<div class="p"><!----></div>
metadatafile specifies the name of the metadata file.  The format of this
file is described below.

<div class="p"><!----></div>
freefile is the name used for the file containing the final PMF and
probability distribution.

<div class="p"><!----></div>
num_MC_trials and randSeed are both related to the performance of Monte
Carlo bootstrap error analysis.  If these values are not supplied, error
analysis is not performed.  num_MC_trials should be an integer specifying
the number of fake data sets which should be generated.  randSeed is an
integer which controls the random number seed - the value you pick should
be irrelevant, but I let the user set it primarily for debugging purposes.

<div class="p"><!----></div>
      <h4><a name="tth_sEc6.1.2">
6.1.2</a>&nbsp;&nbsp;File formats</h4>
<a name="ss:format">
</a>

<div class="p"><!----></div>
Each line of the metadata file should be blank, begin with a "#" (marking a 
comment), or have the following format:

<div class="p"><!----></div>

<pre>
/path/to/timeseries/file&nbsp;&nbsp;&nbsp;&nbsp;loc_win_min&nbsp;&nbsp;&nbsp;spring&nbsp;&nbsp;&nbsp;[correl&nbsp;time]&nbsp;[temperature]

</pre>


<div class="p"><!----></div>
This first field is the name of one of the time series files (more on this
in a moment).  The second field, loc_win_min, is the location of the
minimum of the biasing potential for this simulation, a floating point
number.  The third field, spring, is the spring constant for the biasing
potential used in this simulation, assuming the biasing potential is of the
format 

<div class="p"><!----></div>

<br clear="all" /><table border="0" width="100%"><tr><td>
<table align="center" cellspacing="0"  cellpadding="2"><tr><td nowrap="nowrap" align="center">
V = </td><td nowrap="nowrap" align="center">
1
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>2<br /></td><td nowrap="nowrap" align="center">
k (x&#8722;x<sub>0</sub>)<sup>2</sup>. </td></tr></table>
</td><td width="1%">(1)</td></tr></table>



<div class="p"><!----></div>
Many simulation packages, including TINKER, AMBER, and CHARMM, do not include
the [1/2] when they specify spring constants for their restraint
terms.  This is a common source of error (I'd love to change my code to match
the other packages' behavior, but then experienced users who don't read the
manual would get messed up).  Also, the units for the spring constant must
match those for the time series.  So, if your time series is a distance
recorded in &#197;ngstroms, the spring constant must be in kcal/mol-&#197;<sup>2</sup>.
AMBER users should take care when using angular restraints: the specification
and output of angles is in degrees, but AMBER's spring constants use
kcal/mol-rad<sup>2</sup>.

<div class="p"><!----></div>
The fourth argument ("correl time") specifies the decorrelation time for
your time series, in units of time steps.  It is only used when generating
fake data sets for Monte Carlo bootstrap error analysis, where it modulates
the number of points per fake data set.  This argument is optional, and is
ignored if you don't do error analysis.  If you're doing multiple
temperatures but not bootstrapping, set it to any integer value as a
placeholder, and it'll be ignored.  See section  for more
discussion about how to do bootstrapping.

<div class="p"><!----></div>
Finally, the last (optional) field is the temperature for this simulation.  If
not supplied, the temperature specified on the command line is used.  In
the present version of the code, you must either leave the temperature
unspecified for all simulations or specify it for all simulations.  

<div class="p"><!----></div>
The time series files must follow one of two formats, depending on whether
the temperature was specified in the metadata file.  If no temperature was
specified, the file should contain two columns, where the first is the time
(which isn't actually used), and the second is the position of the system
along the reaction coordinate.  Both numbers should be in floating point
format.  Lines beginning with "#" are ignored as comments.  Additional
columns of data are ignored.

<div class="p"><!----></div>
If the simulation temperature is specified, there must be a third column of
data, containing the system's potential energy at that time point.  It
should be a floating point value.

<div class="p"><!----></div>
      <h4><a name="tth_sEc6.1.3">
6.1.3</a>&nbsp;&nbsp;Output</h4>

<div class="p"><!----></div>
The first line of the output file contains echoes command line.  The next
line or two contain comments describing the periodicity used and the number
of simulation windows present.  
While the calculation is running, it will print out lines that look like
the following:

<pre>
#Iteration&nbsp;10:&nbsp;&nbsp;0.106019
#Iteration&nbsp;20:&nbsp;&nbsp;0.062269
#Iteration&nbsp;30:&nbsp;&nbsp;0.039890
#Iteration&nbsp;40:&nbsp;&nbsp;0.027003

</pre>

<div class="p"><!----></div>
This specifies the current iteration number, and the average change in the
F values for the current iteration.  This number is not used for deciding
when the calculation has converged; rather, the maximum change, as opposed
to the average, is used.  

<div class="p"><!----></div>
Every 100 iterations, the current version of the PMF is dumped into the
output file.  These lines look like

<div class="p"><!----></div>

<pre>
-178.000000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.014212&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4909.138943
-174.000000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.062631&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4525.390035
-170.000000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.227076&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3432.434076
-166.000000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.494262&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2190.487110
-162.000000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.817734&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1271.708620

</pre>

<div class="p"><!----></div>
The first column is the value of the reaction coordinate, the second is the
value of the PMF, and the third is the unnormalized probability
distribution.

<div class="p"><!----></div>
Once the calculation has converged, wham will produce output resembling

<div class="p"><!----></div>

<pre>
#&nbsp;Dumping&nbsp;simulation&nbsp;biases,&nbsp;in&nbsp;the&nbsp;metadata&nbsp;file&nbsp;order&nbsp;
#&nbsp;Window&nbsp;&nbsp;F&nbsp;(free&nbsp;energy&nbsp;units)
#&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000004
#&nbsp;1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-4.166136
#&nbsp;2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-3.241052
#&nbsp;3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-4.475215
#&nbsp;4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-6.324340
#&nbsp;5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-7.128731

</pre>

<div class="p"><!----></div>
These are the final F values from the wham calculation, and can be used for
computing weighted averages for properties other than the free energy.

<div class="p"><!----></div>
You may have noticed that all of the lines except the free energies are
preceded by "#".  This allows you to check convergence of your wham
calculation by simply plotting the output file in gnuplot.  If the free
energy curves have stopped changing, your tolerance is small enough.  

<div class="p"><!----></div>
If you specified a nonzero number of Monte Carlo bootstrap error analysis
trials, you will see lines that resemble

<div class="p"><!----></div>

<pre>
#MC&nbsp;trial&nbsp;0:&nbsp;990&nbsp;iterations
#MC&nbsp;trial&nbsp;1:&nbsp;973&nbsp;iterations
#MC&nbsp;trial&nbsp;2:&nbsp;970&nbsp;iterations
#MC&nbsp;trial&nbsp;3:&nbsp;981&nbsp;iterations
#MC&nbsp;trial&nbsp;4:&nbsp;984&nbsp;iterations

</pre>

<div class="p"><!----></div>
at the end of the file.

<div class="p"><!----></div>
The free energy data file is written when the calculation converges, and
resembles: 

<div class="p"><!----></div>

<pre>
#Coor&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Free&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+/-&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Prob&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+/-
-178.000000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.014386&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000098&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.106389&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000017
-174.000000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.068560&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000151&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.097128&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000025
-170.000000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.250825&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000350&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.071496&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000042
-166.000000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.523786&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000294&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.045186&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000022

</pre>

<div class="p"><!----></div>
The first column is the value of the reaction coordinate, the second is the
free energy.  The third is the statistical uncertainty of the free energy
(which is only meaningful if you performed Monte Carlo bootstrapping).  The
fourth and fifth columns are the probability and it's associated
statistical uncertainty.  Again, the latter is only meaningful if
bootstrapping is performed.  See section  for further
discussion of error estimation.

<div class="p"><!----></div>
     <h3><a name="tth_sEc6.2">
6.2</a>&nbsp;&nbsp;wham-2d</h3>

<div class="p"><!----></div>
      <h4><a name="tth_sEc6.2.1">
6.2.1</a>&nbsp;&nbsp;Command line arguments</h4>

<div class="p"><!----></div>

<pre>
wham-2d&nbsp;Px[=0|pi|val]&nbsp;hist_min_x&nbsp;hist_max_x&nbsp;num_bins_x&nbsp;&nbsp;\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Py[=0|pi|val]&nbsp;hist_min_y&nbsp;hist_max_y&nbsp;num_bins_y&nbsp;&nbsp;\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tol&nbsp;temperature&nbsp;numpad&nbsp;metadatafile&nbsp;freefile&nbsp;\&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;use_mask

</pre>

<div class="p"><!----></div>
The command line arguments largely have the same meaning as they do for the
one dimensional wham program.

<div class="p"><!----></div>
The periodicity arguments are not optional.

<div class="p"><!----></div>
"Px" by itself indicates that the first dimension of the reaction coordinate
has a period of 360.  "Px=0" turns off periodicity.  "Px=pi" specifies a
period of 2*pi, and "Px=val" allows you to choose an arbitrary value for
the period.

<div class="p"><!----></div>
hist_min_x, hist_max_x, and num_bins_x behave exactly like hist_min,
hist_max, and num_bins do in the 1 dimensional program.

<div class="p"><!----></div>
Py, hist_min_y, etc., behave the same as Px, hist_min_x, etc., except they
control the second coordinate of the PMF.

<div class="p"><!----></div>
use_mask expects an integer value, and if its values is non-zero turns on
the automasking feature, which causes bins for which there is no sample data
to be excluded from the wham calculation.

<div class="p"><!----></div>
      <h4><a name="tth_sEc6.2.2">
6.2.2</a>&nbsp;&nbsp;File formats</h4>

<div class="p"><!----></div>
As with regular 1 dimensional wham, each line of the metadata file should
either be blank, begin with a "#", or have the following format

<div class="p"><!----></div>

<pre>
/path/to/timeseries/file&nbsp;loc_win_x&nbsp;loc_win_y&nbsp;spring_x&nbsp;spring_y&nbsp;[correl&nbsp;time]&nbsp;[temp]

</pre>


<div class="p"><!----></div>
This first field is the name of one of the time series files.  loc_win_x
and loc_win_y are the locations of the minimum of the biasing terms in the
first and second dimensions of the reaction coordinate.  spring_x and
spring_y are the spring constants used for the biasing potential in this
simulation, assuming the biasing potential is of the format

<div class="p"><!----></div>

<br clear="all" /><table border="0" width="100%"><tr><td>
<table align="center" cellspacing="0"  cellpadding="2"><tr><td nowrap="nowrap" align="center">
V = </td><td nowrap="nowrap" align="center">
1
<div class="hrcomp"><hr noshade="noshade" size="1"/></div>2<br /></td><td nowrap="nowrap" align="center">
( k<sub>x</sub> (x &#8722; x<sub>0</sub>)<sup>2</sup> + k<sub>y</sub> (y &#8722;y<sub>0</sub>)<sup>2</sup> )</td></tr></table>
</td><td width="1%">(2)</td></tr></table>



<div class="p"><!----></div>
The sixth argument ("correl time") specifies the decorrelation time for
your time series, in units of time steps.  It is only used when generating
fake data sets for Monte Carlo bootstrap error analysis, where it modulates
the number of points per fake data set.  This argument is optional, and is
ignored if you don't do error analysis.  If you're doing multiple
temperatures but not bootstrapping, set it to any integer value as a
placeholder, and it'll be ignored.  See section  for more
discussion about how to do bootstrapping.

<div class="p"><!----></div>
Finally, the last field is the temperature this simulation was run at.  If
not supplied, the temperature specified on the command line is used.  In
the present version of the code, you must either leave the temperature
unspecified for all simulations or specify it for all simulations.  

<div class="p"><!----></div>
The time series files must follow one of two formats, depending on whether
the temperature was specified in the metadata file.  If no temperature was
specified, the file should contain three columns, where the first is the
time (which isn't actually used), and the second and third are the position
of the system along the x and y reaction coordinates, respectively.  Both
numbers should be in floating point format.  Lines beginning with "#" are
ignored as comments.  Additional columns of data are ignored.

<div class="p"><!----></div>
If the simulation temperature is specified, there must be a fourth column of
data, containing the system's potential energy at that time point.  It
should be a floating point value.  See the section on replica exchange for
more details.

<div class="p"><!----></div>
      <h4><a name="tth_sEc6.2.3">
6.2.3</a>&nbsp;&nbsp;Output</h4>

<div class="p"><!----></div>
The output largely resembles that for wham, except with more columns.  The
first line echoes the command line, followed by a specification of the
periodicity, and the number of windows.  The iteration lines have the same
meaning.  When the current value for the PMF is dumped, the format looks
like 

<div class="p"><!----></div>

<pre>
-172.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-172.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.968750&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;15.394489
-172.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-157.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.574512&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.522757
-172.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-142.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.147538&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.094142
-172.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-127.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.505869&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.141952

</pre>
where the first two columns are the values of the first and second
dimensions of the reaction coordinate, the third column is the PMF, and the 
last column is the unnormalized probability.  

<div class="p"><!----></div>
Once the calculation has converged, wham will produce output resembling

<div class="p"><!----></div>

<pre>
#&nbsp;Dumping&nbsp;simulation&nbsp;biases,&nbsp;in&nbsp;the&nbsp;metadata&nbsp;file&nbsp;order&nbsp;
#&nbsp;Window&nbsp;&nbsp;F&nbsp;(free&nbsp;energy&nbsp;units)
#0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-0.000004
#1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-0.156869
#2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-0.534845
#3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-2.445469

</pre>

<div class="p"><!----></div>
These are the final F values from the wham calculation, and can be used for
computing weighted averages for properties other than the free energy.

<div class="p"><!----></div>
If you specified a nonzero number of Monte Carlo bootstrap error analysis
trials, you will see lines that resemble

<div class="p"><!----></div>

<pre>
#MC&nbsp;trial&nbsp;0:&nbsp;990&nbsp;iterations
#MC&nbsp;trial&nbsp;1:&nbsp;973&nbsp;iterations
#MC&nbsp;trial&nbsp;2:&nbsp;970&nbsp;iterations
#MC&nbsp;trial&nbsp;3:&nbsp;981&nbsp;iterations
#MC&nbsp;trial&nbsp;4:&nbsp;984&nbsp;iterations

</pre>
at the end of the file.

<div class="p"><!----></div>
The free energy data file is written when the calculation converges, and
resembles:

<div class="p"><!----></div>

<pre>
-232.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-232.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.812986&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.003185&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000001&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000000
-232.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-217.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.830312&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.003741&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000001&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000000
-232.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-202.500000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.898622&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.001009&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000000&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.000000

</pre>


<div class="p"><!----></div>
The first two columns are the locations along the first and second
dimensions of the reaction coordinate.  The third is the free energy, while
the fourth is the statistical uncertainty in the free energy.  The fifth
and sixth columns are the normalized probability and its statistical
uncertainty.  The two uncertainty columns will be zero if you did not use
Monte Carlo bootstrapping.

<div class="p"><!----></div>
 <h2><a name="tth_sEc7">
7</a>&nbsp;&nbsp;Discussion</h2>

<div class="p"><!----></div>
     <h3><a name="tth_sEc7.1">
7.1</a>&nbsp;&nbsp;Periodicity</h3>

<div class="p"><!----></div>
Use of periodic boundary conditions only changes one thing in the
code: when calculating the biasing potential from a simulation window for a
specific bin in the histogram (the w<sub>j</sub>(X<sub>i</sub>) values in Equation 8 of Roux's
paper, cited above), the minimum image convention is applied.  Thus, for a
window with the biasing potential centered at 175 degrees, the "distance"
to the bin at -175 is 10 degrees, not 350 degrees.

<div class="p"><!----></div>
The numpad argument on the command line is useful primarily for periodic
reaction coordinates.  It specifies a number of additional windows to be
prepended and appended to the final output, such that the periodicity is
explicitly visible in the free energy.  So, if a calculation was done using
360 degree periodicity, 36 windows, with the reaction coordinate ranging
-180 to 180, and numpad=5, a total of 46 values would be output, from -225
to +225.  The numpad value has no effect at all on the values computed for
the PMF and probability.

<div class="p"><!----></div>
     <h3><a name="tth_sEc7.2">
7.2</a>&nbsp;&nbsp;Monte Carlo Bootstrap Error Analysis</h3>
<a name="ss:bootstrap">
</a>

<div class="p"><!----></div>
The premise of bootstrapping error analysis is fairly straightforward.  For
a time series containing N points, choose a set of N points at random,
allowing duplication.  Compute the average from this "fake" data set.
Repeat this procedure a number of times and compute the standard deviation
of the average of the "fake" data sets.  This standard deviation is an
estimate for the statistical uncertainty of the average computed using the
real data.  What this technique really measures is the heterogeneity of the
data set, relative to the number of points present.  For a large enough
number of points, the average value computed using the faked data will be
very close to the value with the real data, with the result that the
standard deviation will be low.  If you have relatively few points, the
deviation will be high.  The technique is quite robust, easy to implement,
and correctly accounts for time correlations in the data.  Numerical
Recipes has a good discussion of the basic logic of this technique.  For a
more detailed discussion, see "An introduction to the bootstrap", by Efron
and Tibshirani (Chapman and Hall/CRC, 1994).  Please note: bootstrapping can
only characterize the data you have.  If your data is missing contributions
from important regions of phase space, bootstrapping will not help you figure
this out.  

<div class="p"><!----></div>
In principle, the standard bootstrap technique could be applied directly to
WHAM calculations.  One could generate a fake data set for each time
series, perform WHAM iterations, and repeat the calculation many times.
However, this would be inefficient, since it would either involve a)
generating many time series in the file system, or b) storing the time
series in memory.  Neither of these strategies is particularly satisfying,
the former because it involves generating a large number of files and the
latter because it would consume very large amounts of memory.  
My implementation of WHAM is very memory efficient because not only does it
not store the time series, it doesn't even store the whole histogram of
that time series, but rather just the nonzero portion.

<div class="p"><!----></div>
However, there is a more efficient alternative.  The principle behind
bootstrapping is that you're trying to establish the various of averages
calculated with N points sampling the true distribution function, using
your current N points of data as an estimate of the true distribution.
The histogram of each time series is precisely that, an estimate of the
probability distribution.  So, all we have to do is pick random numbers
from the distribution defined by that histogram.  Once again, Numerical
Recipes shows us how to do it: we compute the normalized cumulant function,
c(x), generate a random number between 0 and 1 R, and solve c(x) = R 
for x.  Thus, a single Monte Carlo trial is computed in the following manner:

<div class="p"><!----></div>

<ol type="1">
<li> For each simulation window, use the computed cumulant of the histogram
to generate a new histogram, with the same number of points.
<div class="p"><!----></div>
</li>

<li> Perform WHAM iterations on the set of generated histograms
<div class="p"><!----></div>
</li>

<li> Store the average normalized probability and free energy, and their
squares for each bin in the histogram
<div class="p"><!----></div>
</li>
</ol>

<div class="p"><!----></div>
There's a subtlety to how you compute fluctuations in the free energy
estimates, since the potential of mean force is only defined up to a
constant.  I have chosen to align the PMFs by computing them from the
normalized probabilities, which is effectively the same as setting the
Boltzmann-averaged free energies equal.  This is a somewhat arbitrary choice
(for example, one could also set the unweighted averages equal), but it seems
reasonable.  If you want something bulletproof, use the probabilities and
their associated fluctuations, which don't have this problem.

<div class="p"><!----></div>
The situation is slightly more complicated when one attempts to apply the
bootstrap procedure in two dimensions, because the cumulant is not uniquely
defined.  My approach is to flatten the two dimensional histogram into a 1
dimensional distribution, and take the cumulant of that.  The rest of the
procedure is the same as in the 1-D case.  <b>In release 2.0.4, the option
to do 2D bootstrapping has been commented out.  I'm not sure if there's a
programming problem, or implementing the better way of doing the 1D case
simply revealed a deeper problem, but 2D bootstrapping is currently broken.</b>

<div class="p"><!----></div>
There is one major caveat throughout all of this analysis: thus far, we have
assumed that the correlation time in time series is shorter than the snapshot
interval.  To put it another way, we've assumed that all of the data points
are statistically independent.  However, this is unlikely to be the case in a
typical molecular dynamics setting, which means that the sample size used in
the Monte Carlo bootstrapping procedure is too large, which in turn causes
the bootstrapping procedure to underestimate the statistical uncertainty.  

<div class="p"><!----></div>
My code deals with this by allowing you to set the correlation time for each
time series used in the analysis, in effect reducing the number of points
used in generating the fake data sets (see section refss:format).  For
instance, if a time series had 1000 points, and you determined by other means
that the correlation time was 10x the time interval for the time series, then
you would set "correl time" to 10, and each fake data set would have 100
points instead of 1000.  If the value is unset or is greater than the number
of data points, then the full number of data points is used.  Please note
that the actual time values in the time series are not used in any way in
this analysis; for purposes of specifying the correlation time, the interval
between consecutive points is always considered to be 1.

<div class="p"><!----></div>
The question of how to determine the correlation time is in some sense beyond
the scope of this document.  In principle, one could simply compute the
autocorrelation function for each time series; if the autocorrelation is well
approximated by a single exponential, then 2x the decay time (the time it
takes the autocorrelation to drop to 1/e) would be a good choice.  If it's
multiexponential, then you'd use the longest time constant.  However, be
careful: you really want to use the longest correlation time sampled in the
trajectory, and the fluctuations of the reaction coordinate may fluctuate
rapidly but still be coupled to slower modes.  

<div class="p"><!----></div>
It is important to note that the present version of the code uses the
correlation times only for the error analysis and not for the actual PMF
calculation.  This isn't like to be an issue, as the raw PMFs aren't that
sensitive to the correlation times unless they vary by factors of 10 or more.  

<div class="p"><!----></div>
     <h3><a name="tth_sEc7.3">
7.3</a>&nbsp;&nbsp;Using the code for replica exchange simulations</h3>
<a name="ss:repex">
</a>

<div class="p"><!----></div>
One major application for the ability to combine simulations run at different
temperatures is the analysis of replica exchange simulations, and if the
email I've gotten over the last couple of years is any indication, it's a
pretty common one.  My code can be used for replica exchange, but I should
start by admitting that it wasn't designed with it in mind, and may seem a
bit clumsy.  

<div class="p"><!----></div>
First, the metadata file format has changed as of the November, 2007 release
of the code.  If you want to specify temperatures in the metadata file, you
also have to specify the number of Monte Carlo points to use (if you're not
using bootstrapping, you can safely set this to any integer).  See section
<a href="#ss:format">6.1.2</a> for details.

<div class="p"><!----></div>
In order to use wham with time series collected at different temperatures,
the first thing to do is to follow the instructions given in section
<a href="#ss:format">6.1.2</a> regarding the format of the metadata and time series files,
while setting the spring constants to 0.  Indeed, for simple circumstances
involving small systems this may be enough for you to make a successful
calculation.  

<div class="p"><!----></div>
However, for large systems this simple approach will almost certainly get you
nothing but a bunch of NaNs in your output.  If this happens, the most likely
candidate is either a overflow or underflow in the probability histograms.
The reason is that the temperature-sensitive version of the code increments
the histogram by exp(&#8722;E/k<sub>B</sub> T) for each point (as opposed to counting each
point as 1).  Since the potential energies for condensed-phase
molecular dynamics systems using standard force fields are typically of order
-50,000 kcal/mol, the means we'd be taking the exponential of a very large
number, which is a Bad Thing numerically.  

<div class="p"><!----></div>
However, in many circumstances one can work around this easily, by shifting
the location of zero energy.  The simplest procedure is to locate this lowest
energy in any of the trajectories, and shift <em>all</em> of the energies in
<em>all</em> of the trajectories such that the lowest (most negative) value is
now zero.  This will eliminate the overflows, since the largest contribution
from an individual data point will now be 1.  

<div class="p"><!----></div>
However, shifting the energies upward can lead to a different set of
problems, where a given simulation appears to have no probability associated
with it, e.g. the sum of exp(&#8722;E/k<sub>B</sub> T) for the trajectory underflows and
is effectively zero.  This can occur if the energies in the simulation are
significantly higher than those in the lowest energy trajectories, which is
expected for condensed phase systems at high temperatures. Underflow in
itself isn't a problem, but if that simulation is the only one which
contributes to a bin in the histogram (or more generally if all of the
simulations which sample a given bin have zero overall weight), the result
will be a division by zero causing the probability to be NaN or Inf.  

<div class="p"><!----></div>
Solving this problem is sometimes quite simple: reshift the energies by a few
kcal/mol, such that the lowest energy is moderately small instead of zero
(say -5 kcal/mol).  If the problem is just numerical underflow, a small shift
may be sufficient to make the problem numerically well-behaved.  However, if
the relevant portion of the histogram really is unaccessible except at high
temperature, then there may be no way to fix the problem, short of running an
additional umbrella-sampled trajectory.

<div class="p"><!----></div>

<br /><br /><hr /><small>File translated from
T<sub><font size="-1">E</font></sub>X
by <a href="http://hutchinson.belmont.ma.us/tth/">
T<sub><font size="-1">T</font></sub>Hgold</a>,
version 4.00.<br />On 10 Apr 2013, 08:03.</small>
</html>
